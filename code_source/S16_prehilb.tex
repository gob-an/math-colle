\documentclass[a4paper, 12pt]{article}
\usepackage{colle}

\title{Corrigé colle S16 \\ MPI/MPI* du lycée Faidherbe \\ \large Exercices 21, 23, 24, 25}
\author{Léane Parent}

\begin{document}
	\maketitle
	
	\subsection*{Exercice 21}
	%Soit $E$ euclidien, soient $a$, $b \in E$ non nuls. Pour $x\in E \backslash \{0\}$, on note $f(x) = \frac {\scal a x \scal b x} {\|x\|^2}$. Déterminer les bornes inférieure et supérieure de $f$.
	\begin{correctionbox}
		Puisque $f(\lambda x) = f(x)$, il suffit de considérer $\scal a x \scal b x$ où $x$ est unitaire. \\
		On peut de plus, quitte à multiplier le résultat final par $\|a\|\|b\|$ supposer $a$, $b$ unitaires
		
		Sinon, on note $a=u+v$, $b=u-v$ (avec $u = \frac {a+b} 2$, $v=\frac {a-b} 2$), et $u$  et $v$ forment une famille libre. \\
		On a alors $f(x) = \scal {u+v} x \scal {u-v} x = \scal u x ^2 - \scal v x ^2$. \\
		On observe de plus que $u$ et $v$ sont orthogonaux (car $\scal u v = \frac 1 4 \scal {a+b} {a-b} = \|a\|^2 - \|b\|^2=0$), d'où l'on peut décomposer $x = \frac \lambda {\|u\|} u + \frac \mu {\|v\|} v + x'$, avec $x'$ orthogonal à $\Vect (u, v)$. \\
		On obtient donc $f(x)=\lambda^2\|u\| - \mu^2\|v\|$, d'où l'on obtient une borne supérieure à $\|u\|$ en $\frac 1 {\|u\|} u$ de $\|u\|=\frac 1 2 \|a+b\|$, et l'on procède de même pour la borne inférieure ($-\frac 1 2 \|a-b\|$). \\
		(On remarque que cette démonstration fonctionne bien pour $a$, $b$ colinéaires)
	\end{correctionbox}
	
	\subsection*{Exercice 23}
	Soit $n$ un entier naturel.
	\begin{enumerate}
		\item Montrer qu'il existe un unique polynôme $A \in \R_n[X]$ tq, pour $P \in R_n[X]$, $P(1)=\displaystyle \int_{-1}^1 \frac {A(t) P(t)}{\sqrt{1-t^2}} dt$.
		\begin{correctionbox}
			L'évaluation en 1 étant une forme linéaire non nulle, pour tout produit scalaire $\langle \cdot, \cdot \rangle$, il existe un unique $A$ tq $\langle A, \cdot\rangle$ est l'évaluation en 1, car $\R_n[X]$ est de dimension finie. \\
			On note, pour $P$, $Q \in \R_n[X]$ $\langle P, Q \rangle = \displaystyle \int_{-1}^1 \frac {P(t)Q(t)}{\sqrt{1+t^2}}dt$. Montrons que $\langle \cdot, \cdot \rangle$ définit un produit scalaire. \\
			Le caractère défini positif se fait comme usuellement (continu positif d'intégrale nulle...). Le caractère symétrique découle de la commutativité du produit, et la linéarité de celle de l'intégrale. \\
			Ainsi, d'après la remarque précédente, il existe un unique $A$ tq, pour tout $P$, $P(1)=\displaystyle\int_{-1}^1 \frac{A(t)P(t)}{\sqrt{1-t^2}}dt$.
		\end{correctionbox}
		\item Peut-on remplacer $\R_n[X]$ par $\R[X]$?
		\begin{correctionbox}
			A priori non (on n'est plus en dimension finie, ça n'a aucune raison de fonctionner), mais il s'agirait de le montrer. \\
			Le produit scalaire défini ci-dessus reste un produit scalaire sur $\R[X]$. \\
			On suppose qu'il existe un tel $A$. \\
			On écrit $P(X) = (X-1)^2 P(X)$. On a évidemment $P(1) = 0$, d'où par hypothèse $P(1)=\displaystyle\int_{-1}^1 \frac{A(t)P(t)}{\sqrt{1-t^2}}dt$. \\
			Or, $P(X) A(X) = (X-1)^2 A^2(X) \geqslant 0$, et n'est pas identiquement nul (sinon l'intégrale serait nulle pour tout $P$, donc tout polynôme s'annulerait en 1). Dès lors, $t \mapsto \frac {A(t)P(t)} {\sqrt{1-t^2}}$ est continue, positive, non identiquement nulle, donc d'intégrale non nulle sur $[-1,1]$. Dès lors, $P(1) = \displaystyle\int_{-1}^1 \frac{A(t)P(t)}{\sqrt{1-t^2}}dt \not = 0$, ce qui est absurde. On ne peut donc pas remplacer $\R_n[X]$ par $\R[X]$.
		\end{correctionbox}
	\end{enumerate}
	
	\subsection*{Exercice 24}
	Soit $E$ euclidien de dimension $n$. \\
	Soient $x_1, \ \dots\ x_k$ tq, pour $i \not = j$, $\langle x_i, x_j\rangle <0$. Montrer que $k$ ne peut pas être trop grand et trouver cette limite. \\
	(On appellera $(x_1,\ \dots\ x_k)$ une famille obstusangle.) 
	\begin{correctionbox}
		Montrons tout d'abord (par récurrence, vous savez que j'adore ça) qu'il existe une famille obtusangle à $n+1$ éléments
		\begin{itemize}
			\item Si $n=1$, il existe $x$ tq $E=\Vect\ x$. Alors $(x, -x)$ convient.
			\item Soit $n\geqslant 1$. Si $\dim E = n+1$, supposons que pour $F$ sev de $E$ de dimension n, $F$ contient une famille obtusangle à $n+1$ éléments. \\
			On prend $x \not = 0$ dans $E$. Soit $F = \Vect\ x ^\perp$. On considère $(x_1, \ \dots \ x_{n+1})$ famille obtusangle de $F$ (qui existe par hypothèse de récurrence).  \\
			On note, pour $\lambda>0$ $f_\lambda (y) = y - \lambda x$. \\
			D'une part, $\langle x, f_\lambda(x_i) \rangle = -\lambda <0$. De plus, $\langle f_\lambda(x_i), f_\lambda(x_j) \rangle = \langle x_i, x_j \rangle + \lambda^2 \|x\|^2$. Il existe donc $\lambda$ assez petit pour que cette quantité soit négative pour tous $i$, $j$ ($\lambda = -\frac 1 2 \max\langle x_i, x_j \rangle$ convient.) \\
			$(x, x_1,\ \dots,\ x_{n+1})$ est bien obtusangle, ce qui clôt la récurrence.
		\end{itemize}
		\hfill \\
		Montrons maintenant que cette famille est bien la plus grande.
		Montrons d'abord le lemme suivant: si $(x_i)_i$ est obtusangle, et que $\displaystyle \sum_i \lambda_i x_i$ est une combinaison linéaire non triviale annulant les $(x_i)$, alors les $(\lambda_i)$ sont non nuls et de même signe. \\ \\
		On note $I = \left\{i\ |\ \lambda_i <0\right\}$, $J = \left\{i\ |\ \lambda_i \geqslant 0\right\}$ \\
		Puisque la combinaison linéaire est non triviale, il existe $i$ tq $\lambda_i \not = 0$. Quitte à prendre l'opposé de la combinaison linéaire, on peut supposer $\lambda_i > 0$, ie $I \not = \emptyset$ \\
		On a alors: $$\sum_{i\in I} \lambda_i x_i = -\sum_{j\in J} \lambda_j x_j$$
		En notant $S$ la somme de droite, et en prenant le produit scalaire par $S$, on obtient:
		$$\sum_{i,j} \lambda_i \lambda_j \langle x_i,  x_j \rangle = -\|S\|^2 $$
		Or, tous les termes de la somme sont positifs (car les $\lambda_i$ sont positifs, les $\lambda_j$ négatifs, et les $\langle x_i, x_j \rangle$ négatifs car $I$ et $J$ sont disjoints, donc la somme est positive. De plus, le second terme est négatif, donc est nul. \\
		Ainsi, les deux sommes ci-dessus sont nulles. \\ \\
		On suppose $j\in J$ (concrètement, on suppose $J$ non vide). \\
		On a alors:
		$$ 0 = \scal 0 x_j = \scal {\sum_{i\in I} \lambda_i x_i} {x_j} = \sum_{i\in I} \lambda_i \scal {x_i} {x_j}$$
		Or, tous les termes de la somme sont strictement négatifs (car produit d'une quantité strictement négative et d'une strictement positive), et cette somme est non vide car $I\not = 0$ par hypothèse, d'où la somme strictement négative, ce qui est absurde. \\		
		Ceci achève la démonstration du lemme.
		\\ \\
		On suppose que l'on a une famille obtusangle $(x_1,\ \dots\ x_{n+2})$ à $n+2$ éléments. \\
		Puisque $E$ est de dimension $n$, il existe $\lambda_1,\ \dots\ \lambda_{n+1}$ tq $\lambda_1 x_1 + \dots + \lambda_n x_n + \lambda_{n+1} (x_{n+1}-x_{n+2}) = 0$. \\
		Ainsi, $\lambda_{n+1}$ et $-\lambda_{n+1}$ sont tous deux coefficients dans une CL annulant une famille obtusangle: ils non nuls et de même signe, ce qui est absurde: une famille obtusangle à $n+2$ éléments n'existe pas.
	\end{correctionbox}
	
	\subsection*{Exercice 25}
	Soit $E$ un $\R$-ev de dimension finie. Soient $\varphi$, $psi$ deux produits scalaires sur $E$.
	\begin{enumerate}
		\item Montrer l'existence d'un endomorphisme auto-adjoint positif $a$ pour ces deux produits scalaires tel que: $\forall x, y\in E, \varphi(x, y) = \psi\left(a(x), y\right)$
		\begin{correctionbox}
			On fixe $x$ de $E$. $y \mapsto \varphi(x, y)$ étant une forme linéaire, par théorème de représentation des formes linéaires (pour $\psi$)il existe un unique $a(x)$ tq, pour tout $y \in E$, $\varphi(x, y) = \psi(a(x), y)$. On a donc une application $a$ vérifiant cette égalité. Montrons qu'il s'agit d'un endomorphisme autoadjoint positif. \\
			
			La linéarité de $a$ découle immédiatement de la bilinéarité de $\varphi$. \\
			
			De plus, $\psi(x, a(y)) = \psi(a(y), x) = \varphi(y, x) = \varphi(x, y) = \psi(a(x), y)$: $a$ est bien autoadjoint pour $\psi$. \\
			On a également $\varphi(a(x), y) = \psi(a^2(x), y) = \psi(x, a^2(y)) = \varphi(x, y)$. \\
			
			Enfin, $\psi(a(x), x) = \varphi(x, x) \geqslant 0$: $a$ est positif pour $\psi$ (il est d'ailleurs défini positif).
			On a de même que précédemment $\varphi(a(x), x) = \psi(a^2(x), x) = \psi(a(x), a(x)) \geqslant 0$. \\
			
			$a$ est bien un endomorphisme autoadjoint (défini) positif pour les $\varphi$ et $\psi$.
		\end{correctionbox}
		
		\item En utilisant $a$, donner une CNS pour qu'un élément de $O(E, \varphi)$ soit dans $O(E, \psi)$.
		\begin{correctionbox}
			Soit $u \in O(E, \varphi)$. \\
			
			\textbf{condition nécessaire}: On suppose $u\in O(E, \psi)$. On a:
			\begin{align*}
				\varphi (u(x), u(y)) & = \varphi(x, y) \\
				\psi(au(x), u(y) & = \psi(a(x),y) \\
				\psi(u^{-1}au(x), y) & = \psi(a(x), y)
			\end{align*}
			D'où par bilinéarité $\psi(u^{-1}au(x) - a(x), y) = 0$, et pour $y = u^{-1}au(x) - a(x)$, on obtient par définie positivité $u^{-1}au(x) = a(x)$, et ce pour tout $x$, ie $u$ commute avec $a$.\\
			
			\textbf{condition suffisante}: On suppose $u$ commutant avec $a$. \\
			Tout d'abord, on sait que $a$ est inversible, en considérant $a'$ défini tel que pour tout $(x, y)$, $\psi(x, y) = \varphi(a'(x), y)$: il existe bien par symétrie des rôles, et on vérifie aisément que $a' = a^{-1}$. \\
			Pour $x$, $y \in E$, $\psi(u(x), y) = \varphi(a^{-1}u(x), y) = \varphi(ua^{-1}(x), y) = \varphi(a^{-1}(x), u^{-1}(y)) = \psi(x, u^{-1}(y))$: $u$ est bien orthogonal pour $\psi$. \\
			
			Ainsi, $u$ est orthogonal pour $\psi$ ssi $a$ et $u$ commutent.
		\end{correctionbox}
		
		\item Soit $P$ l'ensemble des produits scalaires sur $E$. Déterminer $\displaystyle \bigcap_{\varphi \in P} O(E, \varphi)$.
		\begin{correctionbox}
			On fixe $\phi\in P$. On montre aisément (c'est la même démonstration que la question (1) mais dans l'autre sens) que pour tout $a$ autoadjoint positif (pour $\varphi$), $x, y \mapsto \varphi(a(x), y)$ est un produit scalaire. \\
			
			Dès lors, si $u$ est dans l'intersection, il commute avec tous les endomorphismes autoadjoints positifs pour $\varphi$ (question (2)). \\
			Dès lors, en considérant $\Delta$ diagonale à valeurs propres positives et distinctes, on sait que pour tout $P \in O_n(\R)$ (par analogie matrices-endo), $^tP \Delta P$ commute avec $M$ (en posant $M=Mat_{bc}u$). On obtient en conjuguant par $P$: que $^tPMP$ commute avec $\Delta$, d'où par caractérisation du commutant d'une matrice diagonale, $^tPMP$ est diagonale. (En particulier, pour $P=I_n$, $M$ est diagonale.)\\
			\\
			Montrons maintenant qu'il s'agit d'une homothétie: supposons par l'absurde que $M$ admette deux valeurs propres distinctes $\lambda$, $\mu$. On a alors $M$ orthosemblable à $\mathrm{Diag}(\lambda, \mu, D)$, avec $D$ diagonale. \\
			On pose alors $A = \frac 1 {\sqrt 2} \begin{pmatrix}
				1 & 1 \\
				1 & -1
			\end{pmatrix}$. On vérifie alors que $A$ est orthogonale, et que: \\
			$^t \mathrm{Diag}(A, I_{n-2}) M \mathrm{Diag}(A, I_{n-2}) = \mathrm{Diag}(\frac 1 2 \begin{pmatrix}
				\lambda+\mu & \lambda-\mu \\
				\lambda-\mu & \lambda+\mu
			\end{pmatrix}, D)$. \\
			Or, cette matrice est supposée diagonale d'après ce qui précède, ce qui est absurde (car $\lambda \not = \mu$ d'après notre hypothèse): on a bien toutes les valeurs propres égales: $M$ est une homothétie (donc $u$ également). On note $u = \lambda \id$.
			
			De plus, $u$ est orthogonal, d'où $\varphi(x, x) = \varphi(u(x), u(x)) = \lambda^2\varphi(x, x) $\\
			Ainsi (puisque cette égalité est vraie pour tout $x$, en particulier pour $x$ non nul), $\lambda^2 = \pm 1$, d'où $u=\pm\id$. \\
			
			La réciproque étant immédiate, on a donc: $\displaystyle \bigcap_{\varphi \in P} O(E, \varphi) = \{\pm\id\}$
		\end{correctionbox}
	\end{enumerate}
\end{document}